################
##PACKAGES##
################

library(httr) # GET function 
library(purrr) # map through pages 
library(tibble) # create the air quality data frame 
library(jsonlite) # convert JSON to readable text for R 
library(lubridate) # recognise ymd_hm

################
##RETRIEVING OPENAQ DATA##
################

# Creating a function to fetch a page
fetch_page <- function(page_num) { 
  result <- GET( # get the results from OpenAQ
    "https://api.openaq.org/v3/sensors/2508/measurements/hourly", # 2508 = Sheffield Devonshire Green
    query = list( 
      limit = 1000, # The maximum the API could retrieve for an individual page 
      parameter = "pm25", 
      datetime_from = "2024-01-01T00:00:00Z", 
      datetime_to = "2024-12-31T23:00:00Z",
      page = page_num # Assign and store the page number 
    ),
    add_headers("X-API-Key" = "MY_OPENAQ_API") # X-API-Key is the custom HTTP header used for API authorisation 
  )
  content(result, "parsed") # Returns the results from a string to an integer (JSON -> structured R list) 
}

# Retrieval of all the OpenAQ data from 2024-01-01 - 2024-12-31
first_page <- fetch_page(1) # Get the first 1000 hourly measurements
total_AQ <- first_page$meta$found # Total datapoints including all pages 
total_pages <- ceiling(total_AQ / 1000) # Total pages 
all_AQ_data <- map(1:total_pages, fetch_page) # Loop through all the data found without manual input, calling the fetch_page function to easily get the API 
all_AQ_results <- map(all_AQ_data, "results") %>% unlist(recursive = FALSE) # Retrieval of all the 'results' data and combining it to a single list. Then pipelines the flattened data without flannening everything. 

# Creating a table from all_AQ_results
Sheff_AQ_df <- tibble(
  datetime_from_utc = map_chr(all_AQ_results, ~ .x$period$datetimeFrom$utc %||% NA_character_), # Extracts all the data from datetime_from_utc and creates a column. If data is missing it returns as N/A rather than crashing
  datetime_to_utc = map_chr(all_AQ_results, ~ .x$period$datetimeTo$utc %||% NA_character_), # ~ introduces the formula and .x refers to the current element being processed (shorter for function(x))
  parameter = map_chr(all_AQ_results, ~ .x$parameter$name %||% NA_character_),
  units = map_chr(all_AQ_results, ~ .x$parameter$units %||% NA_character_),
  value = map_dbl(all_AQ_results, ~ .x$value %||% NA_real_),
  avg = map_dbl(all_AQ_results, ~ .x$summary$avg %||% NA_real_)
)

write.csv(Sheff_AQ_df, "Sheffield_PM25_Hourly.csv", row.names = FALSE) # Ready for excel without the row numbers as a first column 

################
##RETRIEVING OPENMETEO DATA##
################

openmeteo_url <- "https://archive-api.open-meteo.com/v1/archive" # Retrieving the link from OpenMeteo

# Creating a request from OpenMeteo
openmeteo <- GET(openmeteo_url, query = list(
  latitude = 53.38, # Same location as 2508 = Sheffield Devonshire Green
  longitude = -1.47, # Same location as 2508 = Sheffield Devonshire Green
  hourly = "rain", 
  start_date = "2024-01-01",
  end_date   = "2024-12-31",
  timezone = "UTC"
))

# Parse the JSON data 
openmeteo_data <- content(openmeteo, as = "text", encoding = "UTF-8") # Encoding tells R how to read the characters.  
openmeteo_flat <- fromJSON(openmeteo_flat, flatten = TRUE) # Converting JSON text to be readable for R by flattening the data 

# Adding the flattened data into columns and rows 
rain_df <- data.frame(
  time = ymd_hm(openmeteo_flat$hourly$time),
  rain_mm = openmeteo_flat$hourly$rain  # values are in millimetres (mm)
)

write.csv(precip, "Sheffield_Rain_Hourly.csv", row.names = FALSE) # Ready for excel without the row numbers as a first column
